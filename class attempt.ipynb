{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification: to do\n",
    "\n",
    "- Import the data\n",
    "- Split the dataset\n",
    "- Train classifiers\n",
    "- k-fold validation\n",
    "- Outcomes\n",
    "- Documentation and report writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datapoints: 1572904\n",
      "Ask Men datapoints: 809290\n",
      "Ask Women datapoints: 763614\n",
      "sum(AM + AW): 1572904\n"
     ]
    }
   ],
   "source": [
    "# Importing data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "with open('FINAL-OUTPUT.txt') as f:\n",
    "    full_data = [line.rstrip('\\n') for line in f]\n",
    "\"\"\"with open('MEN-OUTPUT.txt') as f:\n",
    "    man_data = [line.rstrip('\\n') for line in f]\n",
    "with open('WOMEN-OUTPUT.txt') as f:\n",
    "    woman_data = [line.rstrip('\\n') for line in f]\"\"\"\n",
    "print(\"Total datapoints:\", len(full_data))\n",
    "#print(\"Ask Men datapoints:\", len(man_data))\n",
    "#print(\"Ask Women datapoints:\", len(woman_data))\n",
    "#print(\"sum(AM + AW):\", len(woman_data) + len(man_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of AskMen comments: 809290 809290\n",
      "Number of AskWomen comments: 763614 763614\n",
      "Total comments: 1572904\n"
     ]
    }
   ],
   "source": [
    "# Organise data\n",
    "import json\n",
    "\n",
    "# Total dataset\n",
    "gender = []\n",
    "body = []\n",
    "AMbody = []\n",
    "AMgender = []\n",
    "AWbody = []\n",
    "AWgender = []\n",
    "subreddit = []\n",
    "for line in full_data:\n",
    "    temp = json.loads(line)\n",
    "    body.append(temp['body'])\n",
    "    \n",
    "    \n",
    "    if (temp['author_flair_css_class'] == 'male'):\n",
    "        gender.append(1)\n",
    "    else:\n",
    "        gender.append(0)\n",
    "        \n",
    "    if (temp['subreddit'] == 'AskMen'):\n",
    "        subreddit.append('AM')\n",
    "        AMbody.append(temp['body'])\n",
    "        if (temp['author_flair_css_class'] == 'male'):\n",
    "            AMgender.append(1)\n",
    "        else:\n",
    "            AMgender.append(0)\n",
    "    else:\n",
    "        subreddit.append('AW')\n",
    "        AWbody.append(temp['body'])\n",
    "        if (temp['author_flair_css_class'] == 'male'):\n",
    "            AWgender.append(1)\n",
    "        else:\n",
    "            AWgender.append(0)\n",
    "            \n",
    "print(\"Number of AskMen comments:\", len(AMbody), len(AMgender))\n",
    "print(\"Number of AskWomen comments:\", len(AWbody), len(AWgender))\n",
    "print(\"Total comments:\" , len(AWbody) + len(AMbody))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total amount of men is 863541\n",
      "The total amount of women is 709363\n",
      "The total amount of men in Ask Men is 699471\n",
      "The total amount of women in Ask Men is 109819\n",
      "The total amount of men in Ask Women is 164070\n",
      "The total amount of women in Ask Women is 599544\n"
     ]
    }
   ],
   "source": [
    "print(\"The total amount of men is\", sum(gender))\n",
    "print(\"The total amount of women is\", 1572904-sum(gender))\n",
    "\n",
    "print(\"The total amount of men in Ask Men is\", sum(AMgender))\n",
    "print(\"The total amount of women in Ask Men is\", 809290 -sum(AMgender))\n",
    "\n",
    "print(\"The total amount of men in Ask Women is\", sum(AWgender))\n",
    "print(\"The total amount of women in Ask Women is\", 763614 -sum(AWgender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract meaningful data (total)\n",
    "vectorizer = CountVectorizer()\n",
    "apple = vectorizer.fit_transform(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "# Divide into train and test\n",
    "X_trainS, X_test, y_trainS, y_test = train_test_split(apple, gender, test_size=0.2, random_state=42)\n",
    "# Divide into train and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainS, y_trainS, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOWNSIZE and then split data\n",
    "#Discard \"traash\"\n",
    "X_keep, trash1, y_keep, trash2 = train_test_split(apple, gender, test_size=0.995, random_state=42)\n",
    "print(X_keep.shape, len(y_keep))\n",
    "# Divide into train and test\n",
    "X_trainS, X_test, y_trainS, y_test = train_test_split(X_keep, y_keep, test_size=0.2, random_state=42)\n",
    "# Divide into train and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainS, y_trainS, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract meaningful data (gendered)\n",
    "vectorizer = CountVectorizer()\n",
    "apple = vectorizer.fit(AMbody + AWbody)\n",
    "bodyAM = vectorizer.transform(AMbody)\n",
    "bodyAW = vectorizer.transform(AWbody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (Gendered Male Training)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(bodyAM, AMgender, test_size=0.2, random_state=42)\n",
    "X_test, y_test = bodyAW, AWgender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (Gendered Female Training)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(bodyAW, AWgender, test_size=0.2, random_state=42)\n",
    "X_test, y_test = bodyAM, AMgender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, len(y_train))\n",
    "print(X_test.shape, len(y_test))\n",
    "print(apple.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification time!\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lgClassifier = LogisticRegression(solver='lbfgs')\n",
    "lgClassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification time!\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnbClassifier = MultinomialNB() \n",
    "mnbClassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression: [0.65948824 0.66087889 0.65379266 0.65489152 0.65703727 0.66220297\n",
      " 0.65914329 0.65600413 0.65501073 0.65667965]\n",
      "M. naive Bayes: [0.6481246  0.64768754 0.64723646 0.65020265 0.64869268 0.64809664\n",
      " 0.64527537 0.64905031 0.64622904 0.64436144]\n"
     ]
    }
   ],
   "source": [
    "# Validation time!\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scoresLG2 = cross_val_score(lgClassifier, X_valid, y_valid, cv=10)\n",
    "print(\"Logistic regression:\", scoresLG2)\n",
    "scoresNMB2 = cross_val_score(mnbClassifier, X_valid, y_valid, cv=10)\n",
    "print(\"M. naive Bayes:\", scoresNMB2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression--\n",
      "Accuracy: 0.668403368289884\n",
      "Precision: 0.6605154954065929\n",
      "Recall: 0.8142280355208509\n",
      "F1-score: 0.7293610352950943\n",
      "Area under ROC (ROC AUC) is: 0.6526441339985374\n",
      "\n",
      "\n",
      "Multinomial Naive Bayes--\n",
      "Accuracy: 0.653831604578789\n",
      "Precision: 0.6728427538550825\n",
      "Recall: 0.7185847269609745\n",
      "F1-score: 0.6949618765371235\n",
      "Area under ROC (ROC AUC) is: 0.6468337512930973\n"
     ]
    }
   ],
   "source": [
    "# Test time!\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "y_pred = lgClassifier.predict(X_test)\n",
    "print(\"Logistic Regression--\")\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision:\",precision_score(y_test,y_pred))\n",
    "print(\"Recall:\",recall_score(y_test,y_pred))\n",
    "print(\"F1-score:\",f1_score(y_test,y_pred))\n",
    "auc = roc_auc_score(y_test,y_pred)\n",
    "print('Area under ROC (ROC AUC) is: {}'.format(auc))\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "y_pred = mnbClassifier.predict(X_test)\n",
    "print(\"Multinomial Naive Bayes--\")\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision:\",precision_score(y_test,y_pred))\n",
    "print(\"Recall:\",recall_score(y_test,y_pred))\n",
    "print(\"F1-score:\",f1_score(y_test,y_pred))\n",
    "auc = roc_auc_score(y_test,y_pred)\n",
    "print('Area under ROC (ROC AUC) is: {}'.format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
